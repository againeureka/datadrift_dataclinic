{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milvus Í∏∞Î∞ò ÌÖçÏä§Ìä∏ ÏûÑÎ≤†Îî© Ï†ÄÏû•\n",
    "> üî• Goal\n",
    ">\n",
    ">    1. KLUE/RoBERTaÎ•º Í∏∞Î∞òÏúºÎ°ú Text DataÎ•º EmbeddingÏúºÎ°ú Î≥ÄÌôò\n",
    ">\n",
    ">    2. MilvusÏóê ÏûÑÎ≤†Îî© Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install Milvus\n",
    "- python virtual env; activate milenv \n",
    "    - JupyterÏóêÏÑú Ïù∏ÏãùÎê† Ïàò ÏûàÎèÑÎ°ù ipykernel ÏÑ§Ïπò\n",
    "- [Milvus 2.5](https://milvus.io/docs/ko/install_standalone-docker-compose.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üê≥ Docker Compose Íµ¨ÏÑ± ÌååÏùº Îã§Ïö¥Î°úÎìú\n",
    "\n",
    "!wget https://github.com/milvus-io/milvus/releases/download/v2.5.5/milvus-standalone-docker-compose.yml -O docker-compose.yml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üê≥ Milvus Container Ïã§Ìñâ\n",
    "\n",
    "!sudo docker compose up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úîÔ∏è Install PyMilvus \n",
    "\n",
    "pip install \"pymilvus[model]\" -U "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever Definition\n",
    "\n",
    "Ï†ïÎ≥¥ Í≤ÄÏÉâÏùÑ ÏúÑÌï¥ Ï†ïÏùò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from pymilvus import (\n",
    "    MilvusClient,\n",
    "    DataType,\n",
    "    Function,\n",
    "    FunctionType,\n",
    "    AnnSearchRequest,\n",
    "    RRFRanker,\n",
    ")\n",
    "\n",
    "from pymilvus.model.hybrid import BGEM3EmbeddingFunction\n",
    "\n",
    "\n",
    "class HybridRetriever:\n",
    "    def __init__(self, uri, collection_name=\"hybrid\", dense_embedding_function=None):\n",
    "        self.uri = uri\n",
    "        self.collection_name = collection_name\n",
    "        self.embedding_function = dense_embedding_function\n",
    "        self.use_reranker = True\n",
    "        self.use_sparse = True\n",
    "        self.client = MilvusClient(uri=uri) # Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞\n",
    "\n",
    "    def build_collection(self):\n",
    "        if isinstance(self.embedding_function.dim, dict):\n",
    "            dense_dim = self.embedding_function.dim[\"dense\"]\n",
    "        else:\n",
    "            dense_dim = self.embedding_function.dim\n",
    "\n",
    "        # ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä ÏÑ§Ï†ï\n",
    "        tokenizer_params = {\n",
    "            \"tokenizer\": \"standard\",\n",
    "            \"filter\": [\n",
    "                \"lowercase\",\n",
    "                {\n",
    "                    \"type\": \"length\",\n",
    "                    \"max\": 200,\n",
    "                },\n",
    "                {\"type\": \"stemmer\", \"language\": \"english\"},\n",
    "                {\n",
    "                    \"type\": \"stop\",\n",
    "                    \"stop_words\": [\n",
    "                        \"a\",\n",
    "                        \"an\",\n",
    "                        \"and\",\n",
    "                        \"are\",\n",
    "                        \"as\",\n",
    "                        \"at\",\n",
    "                        \"be\",\n",
    "                        \"but\",\n",
    "                        \"by\",\n",
    "                        \"for\",\n",
    "                        \"if\",\n",
    "                        \"in\",\n",
    "                        \"into\",\n",
    "                        \"is\",\n",
    "                        \"it\",\n",
    "                        \"no\",\n",
    "                        \"not\",\n",
    "                        \"of\",\n",
    "                        \"on\",\n",
    "                        \"or\",\n",
    "                        \"such\",\n",
    "                        \"that\",\n",
    "                        \"the\",\n",
    "                        \"their\",\n",
    "                        \"then\",\n",
    "                        \"there\",\n",
    "                        \"these\",\n",
    "                        \"they\",\n",
    "                        \"this\",\n",
    "                        \"to\",\n",
    "                        \"was\",\n",
    "                        \"will\",\n",
    "                        \"with\",\n",
    "                    ],\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "        \n",
    "        # Milvus Ïª¨Î†âÏÖò Ïä§ÌÇ§Îßà ÏÉùÏÑ±\n",
    "        schema = MilvusClient.create_schema()\n",
    "        schema.add_field(\n",
    "            field_name=\"pk\",\n",
    "            datatype=DataType.VARCHAR,\n",
    "            is_primary=True,\n",
    "            auto_id=True,\n",
    "            max_length=100,\n",
    "        )\n",
    "        schema.add_field(\n",
    "            field_name=\"content\",\n",
    "            datatype=DataType.VARCHAR,\n",
    "            max_length=65535,\n",
    "            analyzer_params=tokenizer_params,\n",
    "            enable_match=True,\n",
    "            enable_analyzer=True,\n",
    "        )\n",
    "        schema.add_field(\n",
    "            field_name=\"sparse_vector\", datatype=DataType.SPARSE_FLOAT_VECTOR\n",
    "        )\n",
    "        schema.add_field(\n",
    "            field_name=\"dense_vector\", datatype=DataType.FLOAT_VECTOR, dim=dense_dim\n",
    "        )\n",
    "        schema.add_field(\n",
    "            field_name=\"original_uuid\", datatype=DataType.VARCHAR, max_length=128\n",
    "        )\n",
    "        schema.add_field(field_name=\"doc_id\", datatype=DataType.VARCHAR, max_length=64)\n",
    "        schema.add_field(\n",
    "            field_name=\"chunk_id\", datatype=DataType.VARCHAR, max_length=64\n",
    "        ),\n",
    "        schema.add_field(field_name=\"original_index\", datatype=DataType.INT32)\n",
    "\n",
    "        # Ïä§ÏΩîÏñ¥ Ï†ÄÏû•\n",
    "        functions = Function(\n",
    "            name=\"bm25\",\n",
    "            function_type=FunctionType.BM25,\n",
    "            input_field_names=[\"content\"],\n",
    "            output_field_names=\"sparse_vector\",\n",
    "        )\n",
    "\n",
    "        schema.add_function(functions)\n",
    "\n",
    "        index_params = MilvusClient.prepare_index_params()\n",
    "        index_params.add_index(\n",
    "            field_name=\"sparse_vector\",\n",
    "            index_type=\"SPARSE_INVERTED_INDEX\",\n",
    "            metric_type=\"BM25\",\n",
    "        )\n",
    "        index_params.add_index(\n",
    "            field_name=\"dense_vector\", index_type=\"FLAT\", metric_type=\"IP\"\n",
    "        )\n",
    "\n",
    "        self.client.create_collection(\n",
    "            collection_name=self.collection_name,\n",
    "            schema=schema,\n",
    "            index_params=index_params,\n",
    "        )\n",
    "\n",
    "    # Îç∞Ïù¥ÌÑ∞ ÏÇΩÏûÖ\n",
    "    def insert_data(self, chunk, metadata):\n",
    "        embedding = self.embedding_function([chunk])\n",
    "        if isinstance(embedding, dict) and \"dense\" in embedding:\n",
    "            dense_vec = embedding[\"dense\"][0]\n",
    "        else:\n",
    "            dense_vec = embedding[0]\n",
    "        self.client.insert(\n",
    "            self.collection_name, {\"dense_vector\": dense_vec, **metadata}\n",
    "        )\n",
    "\n",
    "    # Í≤ÄÏÉâ Í∏∞Îä•\n",
    "    def search(self, query: str, k: int = 20, mode=\"hybrid\"):\n",
    "\n",
    "        output_fields = [\n",
    "            \"content\",\n",
    "            \"original_uuid\",\n",
    "            \"doc_id\",\n",
    "            \"chunk_id\",\n",
    "            \"original_index\",\n",
    "        ]\n",
    "        if mode in [\"dense\", \"hybrid\"]:\n",
    "            embedding = self.embedding_function([query])\n",
    "            if isinstance(embedding, dict) and \"dense\" in embedding:\n",
    "                dense_vec = embedding[\"dense\"][0]\n",
    "            else:\n",
    "                dense_vec = embedding[0]\n",
    "\n",
    "        if mode == \"sparse\":\n",
    "            results = self.client.search(\n",
    "                collection_name=self.collection_name,\n",
    "                data=[query],\n",
    "                anns_field=\"sparse_vector\",\n",
    "                limit=k,\n",
    "                output_fields=output_fields,\n",
    "            )\n",
    "        elif mode == \"dense\":\n",
    "            results = self.client.search(\n",
    "                collection_name=self.collection_name,\n",
    "                data=[dense_vec],\n",
    "                anns_field=\"dense_vector\",\n",
    "                limit=k,\n",
    "                output_fields=output_fields,\n",
    "            )\n",
    "        elif mode == \"hybrid\":\n",
    "            full_text_search_params = {\"metric_type\": \"BM25\"}\n",
    "            full_text_search_req = AnnSearchRequest(\n",
    "                [query], \"sparse_vector\", full_text_search_params, limit=k\n",
    "            )\n",
    "\n",
    "            dense_search_params = {\"metric_type\": \"IP\"}\n",
    "            dense_req = AnnSearchRequest(\n",
    "                [dense_vec], \"dense_vector\", dense_search_params, limit=k\n",
    "            )\n",
    "\n",
    "            results = self.client.hybrid_search(\n",
    "                self.collection_name,\n",
    "                [full_text_search_req, dense_req],\n",
    "                ranker=RRFRanker(),\n",
    "                limit=k,\n",
    "                output_fields=output_fields,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Invalid mode\")\n",
    "        return [\n",
    "            {\n",
    "                \"doc_id\": doc[\"entity\"][\"doc_id\"],\n",
    "                \"chunk_id\": doc[\"entity\"][\"chunk_id\"],\n",
    "                \"content\": doc[\"entity\"][\"content\"],\n",
    "                \"score\": doc[\"distance\"],\n",
    "            }\n",
    "            for doc in results[0]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Milvus Í∏∞Î∞ò ÌïòÏù¥Î∏åÎ¶¨Îìú Í≤ÄÏÉâ ÏãúÏä§ÌÖú\n",
    "- BM25 Í∏∞Î∞ò sparse vector Í≤ÄÏÉâ\n",
    "- DL Í∏∞Î∞ò ÏûÑÎ≤†Îî© Í≤ÄÏÉâ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test Embedding Vector \n",
    "\n",
    "Î≤ïÎ•† Îç∞Ïù¥ÌÑ∞ ÏóÖÎ°úÎìú ÏóÜÏù¥ MilvusÎßå ÌÖåÏä§Ìä∏\n",
    "- Ï†ÄÏû•Îêú Îç∞Ïù¥ÌÑ∞ Í≤ÄÏÉâ Î∞è Ï°∞Ìöå"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "MODEL_NAME = \"klue/roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device) \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()  \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Data in Milvus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [create index](https://milvus.io/api-reference/pymilvus/v2.3.x/MilvusClient/Management/create_index.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient, DataType\n",
    "\n",
    "client = MilvusClient(uri=\"http://localhost:19530\")\n",
    "\n",
    "collection_name = \"klue_roberta_embeddings\"\n",
    "\n",
    "# Ïª¨ÎûôÏÖò ÏÉùÏÑ±\n",
    "schema = MilvusClient.create_schema()\n",
    "schema.add_field(\"id\", DataType.INT64, is_primary=True, auto_id=True)\n",
    "schema.add_field(\"content\", DataType.VARCHAR, max_length=1024)  # ÏõêÎ≥∏ ÌÖçÏä§Ìä∏ Ï†ÄÏû•\n",
    "schema.add_field(\"vector\", DataType.FLOAT_VECTOR, dim=768)  # KLUE/RoBERTa ÏûÑÎ≤†Îî© Ï†ÄÏû•\n",
    "\n",
    "client.create_collection(collection_name=collection_name, schema=schema)\n",
    "\n",
    "# Î≤°ÌÑ∞ ÌïÑÎìúÏóê ÎåÄÌïú Ïù∏Îç±Ïä§ ÏÉùÏÑ±\n",
    "index_params = client.prepare_index_params()\n",
    "index_params.add_index(\n",
    "    field_name=\"vector\",\n",
    "    index_type=\"IVF_FLAT\",\n",
    "    metric_type=\"L2\",\n",
    "    params={\"nlist\": 128}\n",
    ")\n",
    "client.create_index(collection_name, index_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"ÌïúÍµ≠Ïùò Ïù∏Í≥µÏßÄÎä• Ïó∞Íµ¨Îäî Îπ†Î•¥Í≤å Î∞úÏ†ÑÌïòÍ≥† ÏûàÏäµÎãàÎã§.\",\n",
    "    \"MilvusÎäî Î≤°ÌÑ∞ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏûÖÎãàÎã§.\",\n",
    "    \"Î°úÎ¥á Í≥µÌïôÍ≥º Îî•Îü¨ÎãùÏùÄ Î∞ÄÏ†ëÌïú Í¥ÄÎ†®Ïù¥ ÏûàÏäµÎãàÎã§.\"\n",
    "]\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î≥ÄÌôò Î∞è Milvus ÏÇΩÏûÖ\n",
    "for text in data:\n",
    "    embedding = get_embedding(text) \n",
    "    client.insert(collection_name, [{\"content\": text, \"vector\": embedding.tolist()}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['klue_roberta_embeddings']\n"
     ]
    }
   ],
   "source": [
    "# MilvusÏóê Ï†ÄÏû•Îêú Î™®Îì† Ïª¨Î†âÏÖò ÌôïÏù∏\n",
    "print(client.list_collections())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'collection_name': 'klue_roberta_embeddings', 'auto_id': True, 'num_shards': 1, 'description': '', 'fields': [{'field_id': 100, 'name': 'id', 'description': '', 'type': <DataType.INT64: 5>, 'params': {}, 'auto_id': True, 'is_primary': True}, {'field_id': 101, 'name': 'content', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 1024}}, {'field_id': 102, 'name': 'vector', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 768}}], 'functions': [], 'aliases': [], 'collection_id': 456592164736288327, 'consistency_level': 2, 'properties': {}, 'num_partitions': 1, 'enable_dynamic_field': False, 'created_timestamp': 456610227358269446}\n",
      "['vector']\n"
     ]
    }
   ],
   "source": [
    "# Vector DB Í≤ÄÏÉâ ÏàòÌñâÏùÑ ÏúÑÌï¥ Ïù∏Îç±Ïä§ ÏÉùÏÑ± Ïú†Î¨¥ ÌååÏïÖ\n",
    "print(client.describe_collection(collection_name))\n",
    "print(client.list_indexes(collection_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå ÌïúÍµ≠Ïùò Ïù∏Í≥µÏßÄÎä• Ïó∞Íµ¨Îäî Îπ†Î•¥Í≤å Î∞úÏ†ÑÌïòÍ≥† ÏûàÏäµÎãàÎã§. (Ïú†ÏÇ¨ÎèÑ: 1.2914175987243652)\n",
      "üìå ÌïúÍµ≠Ïùò Ïù∏Í≥µÏßÄÎä• Ïó∞Íµ¨Îäî Îπ†Î•¥Í≤å Î∞úÏ†ÑÌïòÍ≥† ÏûàÏäµÎãàÎã§. (Ïú†ÏÇ¨ÎèÑ: 1.2914175987243652)\n",
      "üìå Î°úÎ¥á Í≥µÌïôÍ≥º Îî•Îü¨ÎãùÏùÄ Î∞ÄÏ†ëÌïú Í¥ÄÎ†®Ïù¥ ÏûàÏäµÎãàÎã§. (Ïú†ÏÇ¨ÎèÑ: 1.7175631523132324)\n"
     ]
    }
   ],
   "source": [
    "# Ïª¨Î†âÏÖò Î°úÎìú\n",
    "client.load_collection(collection_name)\n",
    "\n",
    "query = \"AI Ïó∞Íµ¨Í∞Ä Îπ†Î•¥Í≤å ÏßÑÌñâ Ï§ëÏù¥Îã§.\"\n",
    "query_vector = get_embedding(query) \n",
    "\n",
    "# MilvusÏóêÏÑú Í≤ÄÏÉâ\n",
    "results = client.search(\n",
    "    collection_name=collection_name,\n",
    "    data=[query_vector],\n",
    "    anns_field=\"vector\",\n",
    "    limit=3, \n",
    "    output_fields=[\"content\"]\n",
    ")\n",
    "\n",
    "# Í≤ÄÏÉâ Í≤∞Í≥º Ï∂úÎ†•\n",
    "for doc in results[0]:\n",
    "    print(f\"üìå {doc['entity']['content']} (Ïú†ÏÇ¨ÎèÑ: {doc['distance']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Streamlit Dashboard ÏµúÏ†ÅÌôî "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "milenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
